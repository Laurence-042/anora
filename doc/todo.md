你精准地踩到了“引用传递”架构中最难受的坑：**当逻辑和数据分布在不同端时，如何高效处理集合（Collection）？**

在你的需求中，“读取”和“过滤”都在后端（处理大文件），但“循环处理”通常涉及到业务逻辑分支，前端（ANORA 控制面）需要感知每一次循环。如果每次循环都让后端传一行数据给前端，那 1GB 的文件还是会把连接带宽撑爆。

作为 **PL 架构师**，针对 ANORA 的节点设计，我建议采用 **“流式游标 (Streaming Cursor)”** 或 **“延迟代理 (Lazy Proxy)”** 的设计模式。

### 1. 核心概念：不要把 Handle 看作一个死文件，而是一个“数据源”

在你的节点系统中，可以将输出分为两类：

- **Scalar Handle (标量句柄)：** 指向单个对象（如一个已解析的配置）。
- **Iterator Handle (迭代器句柄)：** 指向一个**待处理的序列**。

### 2. 具体执行逻辑流

针对你的“过滤 + 循环”需求，ANORA 的节点执行逻辑应该是这样的：

1. **Read File 节点 (后端执行)：**
   - 读取 1GB 文件。
   - 输出一个 `IteratorHandle`（实际上只是一个 ID，比如 `iter_001`）。
2. **Filter 节点 (后端执行)：**
   - 输入 `iter_001` + 过滤规则（正则/关键词）。
   - 后端在内部创建一个**虚拟视图**（Virtual View），并不实际产生新文件。
   - 输出一个新的 `IteratorHandle` (`iter_002`)。此时前端依然没有任何实际行数据。
3. **Loop/For-Each 节点 (前后端协作)：**
   - 这是最关键的节点。它接收 `iter_002`。
   - **策略 A（分批拉取）：** 前端向后端发送 `next_batch(iter_002, count=100)`。后端只返回这 100 行。
   - **策略 B（流式回调）：** 后端每处理完一行，如果需要前端介入，就发一个 IPC 消息。

### 3. 如何在 ANORA 节点中优雅地表达？

在你的 `story-working.md` 架构下，可以为 **Port（端口）** 增加一个类型：`Stream`。

- **对于 PL 来说：** 你在画布上看到的是一条粗线（表示大量数据流过）。
- **对于 Executor 来说：** 当它遇到一个连接了 `Stream` 端口的 `Loop` 节点时，它不尝试一次性获取数据，而是进入 **“订阅模式”**。

JavaScript

```
// 伪代码：Executor 处理 Iterator Handle
async function activateLoopNode(node, context) {
    const handle = node.input.get('iterator'); 
    
    // 向后端请求“开启流式读取”
    const stream = await backend.openStream(handle);
    
    while (await stream.hasNext()) {
        const row = await stream.getNextChunk(); // 每次只拿一小块数据
        // 将这一块数据放入 Context，触发循环体内的子节点
        await executeSubGraph(node.body, { ...context, currentRow: row });
        
        // 性能优化：每 1000 次循环强制释放一次 UI 线程
        if (loopCount++ % 1000 === 0) await yieldToUI();
    }
}
```

### 4. 终极优化：谓词下推 (Predicate Pushdown)

为了避免前端在循环里做太多的微小操作，你可以设计一种 **“复合节点”**。

- **不要：** [读取] -> [循环] -> [前端判断是否包含"Error"] -> [处理]。
- **要：** [读取] -> [后端过滤节点(输入"Error")] -> [循环] -> [处理]。

这就是数据库领域常用的“谓词下推”：**尽可能把逻辑推给靠近数据的那一端（后端）去执行，前端只拿最终需要处理的结果。**

### 总结给 ANORA 的架构建议：

1. **引入迭代器句柄：** 节点之间传递的是“待处理清单的入场券”，而不是清单本身。
2. **后端实现“惰性计算”：** 只有当前端 Loop 节点明确要求 `next()` 时，后端才真正去读下一行。
3. **UI 采样：** 在前端画布上，只给用户看这个 Handle 的前 5 行采样数据，方便用户写过滤规则，剩下的 1,000,000 行留在后端黑盒里跑。

这种设计不仅解决了大文件问题，还顺便解决了你担心的 **“执行线程卡死”**，因为最重的活（读取和过滤）都由后端异步完成了，前端只是在“点名”而已。